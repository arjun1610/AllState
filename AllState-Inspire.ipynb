{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from scipy.stats import skew, boxcox\n",
    "from math import exp, log\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def timer(start_time=None):\n",
    "    if not start_time:\n",
    "        start_time = datetime.now()\n",
    "        return start_time\n",
    "    elif start_time:\n",
    "        tmin, tsec = divmod((datetime.now() - start_time).total_seconds(), 60)\n",
    "        print(' Time taken: %i minutes and %s seconds.' %\n",
    "              (tmin, round(tsec, 2)))\n",
    "\n",
    "\n",
    "def scale_data(X, scaler=None):\n",
    "    if not scaler:\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    return X, scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "DATA_TRAIN_PATH = 'input/train.csv'\n",
    "DATA_TEST_PATH = 'input/test.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_data(path_train=DATA_TRAIN_PATH, path_test=DATA_TEST_PATH):\n",
    "    train_loader = pd.read_csv(path_train, dtype={'id': np.int32})\n",
    "    train = train_loader.drop(['id', 'loss'], axis=1)\n",
    "    test_loader = pd.read_csv(path_test, dtype={'id': np.int32})\n",
    "    test = test_loader.drop(['id'], axis=1)\n",
    "    ntrain = train.shape[0]\n",
    "    ntest = test.shape[0]\n",
    "    train_test = pd.concat((train, test)).reset_index(drop=True)\n",
    "    numeric_feats = train_test.dtypes[train_test.dtypes != \"object\"].index\n",
    "\n",
    "    # compute skew and do Box-Cox transformation\n",
    "    skewed_feats = train[numeric_feats].apply(lambda x: skew(x.dropna()))\n",
    "    print(\"\\nSkew in numeric features:\")\n",
    "    print(skewed_feats)\n",
    "    # transform features with skew > 0.25 (this can be varied to find optimal value)\n",
    "    skewed_feats = skewed_feats[skewed_feats > 0.25]\n",
    "    skewed_feats = skewed_feats.index\n",
    "    for feats in skewed_feats:\n",
    "        train_test[feats] = train_test[feats] + 1\n",
    "        train_test[feats], lam = boxcox(train_test[feats])\n",
    "    features = train.columns\n",
    "    cats = [feat for feat in features if 'cat' in feat]\n",
    "    # factorize categorical features\n",
    "    for feat in cats:\n",
    "        train_test[feat] = pd.factorize(train_test[feat], sort=True)[0]\n",
    "    x_train = train_test.iloc[:ntrain, :]\n",
    "    x_test = train_test.iloc[ntrain:, :]\n",
    "    train_test_scaled, scaler = scale_data(train_test)\n",
    "    train, _ = scale_data(x_train, scaler)\n",
    "    test, _ = scale_data(x_test, scaler)\n",
    "\n",
    "    train_labels = np.log(np.array(train_loader['loss']))\n",
    "    train_ids = train_loader['id'].values.astype(np.int32)\n",
    "    test_ids = test_loader['id'].values.astype(np.int32)\n",
    "\n",
    "    return train, train_labels, test, train_ids, test_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skew in numeric features:\n",
      "cont1     0.516420\n",
      "cont2    -0.310939\n",
      "cont3    -0.010002\n",
      "cont4     0.416093\n",
      "cont5     0.681617\n",
      "cont6     0.461211\n",
      "cont7     0.826046\n",
      "cont8     0.676629\n",
      "cont9     1.072420\n",
      "cont10    0.354998\n",
      "cont11    0.280819\n",
      "cont12    0.291990\n",
      "cont13    0.380739\n",
      "cont14    0.248672\n",
      "dtype: float64\n",
      "\n",
      " Fold 1\n",
      "\n",
      "\n",
      " Fold 2\n",
      "\n",
      "\n",
      " Fold 3\n",
      "\n",
      "\n",
      " Fold 4\n",
      "\n",
      "\n",
      " Fold 5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# enter the number of folds from xgb.cv\n",
    "folds = 5\n",
    "cv_sum = 0\n",
    "early_stopping = 25\n",
    "fpred = []\n",
    "xgb_rounds = []\n",
    "\n",
    "start_time = timer(None)\n",
    "\n",
    "# Load data set and target values\n",
    "train, target, test, _, ids = load_data()\n",
    "d_train_full = xgb.DMatrix(train, label=target)\n",
    "d_test = xgb.DMatrix(test)\n",
    "\n",
    "# set up KFold that matches xgb.cv number of folds\n",
    "kf = KFold(train.shape[0], n_folds=folds)\n",
    "for i, (train_index, test_index) in enumerate(kf):\n",
    "    print('\\n Fold %d\\n' % (i + 1))\n",
    "    X_train, X_val = train[train_index], train[test_index]\n",
    "    y_train, y_val = target[train_index], target[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################################\n",
    "#\n",
    "# Define cross-validation variables\n",
    "#\n",
    "#######################################\n",
    "\n",
    "    params = {}\n",
    "    params['booster'] = 'gbtree'\n",
    "    params['objective'] = \"reg:linear\"\n",
    "    params['eval_metric'] = 'mae'\n",
    "    params['eta'] = 0.1\n",
    "    params['gamma'] = 0.5290\n",
    "    params['min_child_weight'] = 4.2922\n",
    "    params['colsample_bytree'] = 0.3085\n",
    "    params['subsample'] = 0.9930\n",
    "    params['max_depth'] = 7\n",
    "    params['max_delta_step'] = 0\n",
    "    params['silent'] = 1\n",
    "    params['random_state'] = 1001\n",
    "\n",
    "    d_train = xgb.DMatrix(X_train, label=y_train)\n",
    "    d_valid = xgb.DMatrix(X_val, label=y_val)\n",
    "    watchlist = [(d_train, 'train'), (d_valid, 'eval')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################################\n",
    "#  Build Model\n",
    "####################################\n",
    "\n",
    "    clf = xgb.train(params,\n",
    "                    d_train,\n",
    "                    100000,\n",
    "                    watchlist,\n",
    "                    early_stopping_rounds=early_stopping)\n",
    "\n",
    "####################################\n",
    "#  Evaluate Model and Predict\n",
    "####################################\n",
    "\n",
    "    xgb_rounds.append(clf.best_iteration)\n",
    "    scores_val = clf.predict(d_valid, ntree_limit=clf.best_ntree_limit)\n",
    "    cv_score = mean_absolute_error(np.exp(y_val), np.exp(scores_val))\n",
    "    print(' eval-MAE: %.6f' % cv_score)\n",
    "    y_pred = np.exp(clf.predict(d_test, ntree_limit=clf.best_ntree_limit))\n",
    "\n",
    "####################################\n",
    "#  Add Predictions and Average Them\n",
    "####################################\n",
    "\n",
    "    if i > 0:\n",
    "        fpred = pred + y_pred\n",
    "    else:\n",
    "        fpred = y_pred\n",
    "    pred = fpred\n",
    "    cv_sum = cv_sum + cv_score\n",
    "\n",
    "mpred = pred / folds\n",
    "score = cv_sum / folds\n",
    "print('\\n Average eval-MAE: %.6f' % score)\n",
    "n_rounds = int(np.mean(xgb_rounds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################################\n",
    "#  Make Full Dataset Predictions\n",
    "####################################\n",
    "\n",
    "print('\\n Training full dataset for %d rounds ...' % n_rounds)\n",
    "watchlist = [(d_train_full, 'train')]\n",
    "clf_full = xgb.train(\n",
    "    params, d_train_full,\n",
    "    n_rounds,\n",
    "    watchlist,\n",
    "    verbose_eval=False,)\n",
    "y_pred_full = np.exp(clf_full.predict(d_test))\n",
    "\n",
    "# enter the number of iterations from xgb.cv with early_stopping turned on\n",
    "n_fixed = 376\n",
    "\n",
    "nfixed = int(n_fixed * (1 + (1. / folds)))\n",
    "print('\\n Training full dataset for %d rounds ...\\n' % nfixed)\n",
    "clf_fixed = xgb.train(\n",
    "    params, d_train_full,\n",
    "    nfixed,\n",
    "    watchlist,\n",
    "    verbose_eval=False,)\n",
    "y_pred_fixed = np.exp(clf_fixed.predict(d_test))\n",
    "timer(start_time)\n",
    "\n",
    "print(\"#\\n Writing results\")\n",
    "result = pd.DataFrame(mpred, columns=['loss'])\n",
    "result[\"id\"] = ids\n",
    "result = result.set_index(\"id\")\n",
    "print(\"\\n %d-fold average prediction:\\n\" % folds)\n",
    "print(result.head())\n",
    "result_full = pd.DataFrame(y_pred_full, columns=['loss'])\n",
    "result_full[\"id\"] = ids\n",
    "result_full = result_full.set_index(\"id\")\n",
    "print(\"\\n Full dataset prediction:\\n\")\n",
    "print(result_full.head())\n",
    "result_fixed = pd.DataFrame(y_pred_fixed, columns=['loss'])\n",
    "result_fixed[\"id\"] = ids\n",
    "result_fixed = result_fixed.set_index(\"id\")\n",
    "print(\"\\n Full datset (at CV #iterations) prediction:\\n\")\n",
    "print(result_fixed.head())\n",
    "\n",
    "now = datetime.now()\n",
    "score = str(round((cv_sum / folds), 6))\n",
    "sub_file = 'submission_5fold-average-xgb_' + str(score) + '_' + str(\n",
    "    now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "print(\"\\n Writing submission: %s\" % sub_file)\n",
    "result.to_csv(sub_file, index=True, index_label='id')\n",
    "sub_file = 'submission_full-average-xgb_' + str(now.strftime(\n",
    "    \"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "print(\"\\n Writing submission: %s\" % sub_file)\n",
    "result_full.to_csv(sub_file, index=True, index_label='id')\n",
    "sub_file = 'submission_full-CV-xgb_' + str(now.strftime(\n",
    "    \"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "print(\"\\n Writing submission: %s\" % sub_file)\n",
    "result_fixed.to_csv(sub_file, index=True, index_label='id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
